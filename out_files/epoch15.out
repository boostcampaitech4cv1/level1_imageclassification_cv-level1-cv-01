/opt/conda/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
wandb: Currently logged in as: qwer55252. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.4
wandb: Run data is saved locally in /opt/ml/project-T4193/wandb/run-20221028_095728-2rxznn66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-disco-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/qwer55252/Boostcamp-lv1-cv1
wandb: üöÄ View run at https://wandb.ai/qwer55252/Boostcamp-lv1-cv1/runs/2rxznn66
Loaded pretrained weights for efficientnet-b7
EfficientNet(
  (_conv_stem): Conv2dStaticSamePadding(
    3, 64, kernel_size=(3, 3), stride=(2, 2), bias=False
    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)
  )
  (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
  (_blocks): ModuleList(
    (0): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        64, 64, kernel_size=(3, 3), stride=[1, 1], groups=64, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        64, 16, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        16, 64, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (1): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        32, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 32, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (2): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        32, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 32, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (3): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        32, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 32, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (4): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False
        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        192, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 192, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (5): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (6): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (7): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (8): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (9): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (10): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (11): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(5, 5), stride=[2, 2], groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (12): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (13): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (14): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (15): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (16): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (17): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (18): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(3, 3), stride=[2, 2], groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (19): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (20): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (21): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (22): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (23): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (24): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (25): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (26): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (27): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (28): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(5, 5), stride=[1, 1], groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (29): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (30): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (31): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (32): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (33): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (34): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (35): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (36): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (37): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (38): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=[2, 2], groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (39): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (40): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (41): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (42): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (43): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (44): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (45): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (46): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (47): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (48): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (49): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (50): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (51): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(3, 3), stride=[1, 1], groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (52): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        3840, 160, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        160, 3840, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (53): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        3840, 160, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        160, 3840, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (54): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        3840, 160, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        160, 3840, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
  )
  (_conv_head): Conv2dStaticSamePadding(
    640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False
    (static_padding): Identity()
  )
  (_bn1): BatchNorm2d(2560, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)
  (_dropout): Dropout(p=0.5, inplace=False)
  (_fc): Linear(in_features=2560, out_features=18, bias=True)
  (_swish): MemoryEfficientSwish()
)
Train Epoch: 1 [0/19430 (0%)] Loss: 2.898180
Train Epoch: 1 [160/19430 (1%)] Loss: 2.063871
Train Epoch: 1 [320/19430 (2%)] Loss: 1.389970
Train Epoch: 1 [480/19430 (2%)] Loss: 1.600314
Train Epoch: 1 [640/19430 (3%)] Loss: 0.713331
Train Epoch: 1 [800/19430 (4%)] Loss: 0.794222
Train Epoch: 1 [960/19430 (5%)] Loss: 1.287589
Train Epoch: 1 [1120/19430 (6%)] Loss: 1.136025
Train Epoch: 1 [1280/19430 (7%)] Loss: 0.741114
Train Epoch: 1 [1440/19430 (7%)] Loss: 1.103026
Train Epoch: 1 [1600/19430 (8%)] Loss: 0.948082
Train Epoch: 1 [1760/19430 (9%)] Loss: 0.851384
Train Epoch: 1 [1920/19430 (10%)] Loss: 0.762241
Train Epoch: 1 [2080/19430 (11%)] Loss: 0.849921
Train Epoch: 1 [2240/19430 (12%)] Loss: 0.997967
Train Epoch: 1 [2400/19430 (12%)] Loss: 0.714713
Train Epoch: 1 [2560/19430 (13%)] Loss: 0.319348
Train Epoch: 1 [2720/19430 (14%)] Loss: 0.854263
Train Epoch: 1 [2880/19430 (15%)] Loss: 0.438857
Train Epoch: 1 [3040/19430 (16%)] Loss: 0.607836
Train Epoch: 1 [3200/19430 (16%)] Loss: 0.631922
Train Epoch: 1 [3360/19430 (17%)] Loss: 0.622773
Train Epoch: 1 [3520/19430 (18%)] Loss: 1.081160
Train Epoch: 1 [3680/19430 (19%)] Loss: 0.357174
Train Epoch: 1 [3840/19430 (20%)] Loss: 0.613256
Train Epoch: 1 [4000/19430 (21%)] Loss: 0.457038
Train Epoch: 1 [4160/19430 (21%)] Loss: 0.630971
Train Epoch: 1 [4320/19430 (22%)] Loss: 0.707863
Train Epoch: 1 [4480/19430 (23%)] Loss: 1.241664
Train Epoch: 1 [4640/19430 (24%)] Loss: 0.561655
Train Epoch: 1 [4800/19430 (25%)] Loss: 1.024708
Train Epoch: 1 [4960/19430 (26%)] Loss: 0.477819
Train Epoch: 1 [5120/19430 (26%)] Loss: 0.564474
Train Epoch: 1 [5280/19430 (27%)] Loss: 0.378202
Train Epoch: 1 [5440/19430 (28%)] Loss: 0.759812
Train Epoch: 1 [5600/19430 (29%)] Loss: 0.552477
Train Epoch: 1 [5760/19430 (30%)] Loss: 0.297424
Train Epoch: 1 [5920/19430 (30%)] Loss: 0.395277
Train Epoch: 1 [6080/19430 (31%)] Loss: 0.353592
Train Epoch: 1 [6240/19430 (32%)] Loss: 0.448418
Train Epoch: 1 [6400/19430 (33%)] Loss: 0.456661
Train Epoch: 1 [6560/19430 (34%)] Loss: 0.355937
Train Epoch: 1 [6720/19430 (35%)] Loss: 0.488645
Train Epoch: 1 [6880/19430 (35%)] Loss: 0.324843
Train Epoch: 1 [7040/19430 (36%)] Loss: 0.736646
Train Epoch: 1 [7200/19430 (37%)] Loss: 0.587357
Train Epoch: 1 [7360/19430 (38%)] Loss: 0.374094
Train Epoch: 1 [7520/19430 (39%)] Loss: 0.338335
Train Epoch: 1 [7680/19430 (40%)] Loss: 0.539290
Train Epoch: 1 [7840/19430 (40%)] Loss: 0.609339
Train Epoch: 1 [8000/19430 (41%)] Loss: 0.282076
Train Epoch: 1 [8160/19430 (42%)] Loss: 0.398143
Train Epoch: 1 [8320/19430 (43%)] Loss: 0.562239
Train Epoch: 1 [8480/19430 (44%)] Loss: 0.216774
Train Epoch: 1 [8640/19430 (44%)] Loss: 0.234657
Train Epoch: 1 [8800/19430 (45%)] Loss: 0.241999
Train Epoch: 1 [8960/19430 (46%)] Loss: 0.263150
Train Epoch: 1 [9120/19430 (47%)] Loss: 0.482288
Train Epoch: 1 [9280/19430 (48%)] Loss: 0.231179
Train Epoch: 1 [9440/19430 (49%)] Loss: 0.365872
Train Epoch: 1 [9600/19430 (49%)] Loss: 0.115212
Train Epoch: 1 [9760/19430 (50%)] Loss: 0.471437
Train Epoch: 1 [9920/19430 (51%)] Loss: 0.270632
Train Epoch: 1 [10080/19430 (52%)] Loss: 0.312569
Train Epoch: 1 [10240/19430 (53%)] Loss: 0.491697
Train Epoch: 1 [10400/19430 (54%)] Loss: 0.142061
Train Epoch: 1 [10560/19430 (54%)] Loss: 0.567546
Train Epoch: 1 [10720/19430 (55%)] Loss: 0.538054
Train Epoch: 1 [10880/19430 (56%)] Loss: 0.368520
Train Epoch: 1 [11040/19430 (57%)] Loss: 0.418563
Train Epoch: 1 [11200/19430 (58%)] Loss: 0.434157
Train Epoch: 1 [11360/19430 (58%)] Loss: 0.309030
Train Epoch: 1 [11520/19430 (59%)] Loss: 0.146926
Train Epoch: 1 [11680/19430 (60%)] Loss: 0.343899
Train Epoch: 1 [11840/19430 (61%)] Loss: 0.369326
Train Epoch: 1 [12000/19430 (62%)] Loss: 0.475580
Train Epoch: 1 [12160/19430 (63%)] Loss: 0.291763
Train Epoch: 1 [12320/19430 (63%)] Loss: 0.248187
Train Epoch: 1 [12480/19430 (64%)] Loss: 0.171781
Train Epoch: 1 [12640/19430 (65%)] Loss: 0.195619
Train Epoch: 1 [12800/19430 (66%)] Loss: 0.756956
Train Epoch: 1 [12960/19430 (67%)] Loss: 0.085515
Train Epoch: 1 [13120/19430 (68%)] Loss: 0.544890
Train Epoch: 1 [13280/19430 (68%)] Loss: 0.427562
Train Epoch: 1 [13440/19430 (69%)] Loss: 0.203656
Train Epoch: 1 [13600/19430 (70%)] Loss: 0.316588
Train Epoch: 1 [13760/19430 (71%)] Loss: 0.293158
Train Epoch: 1 [13920/19430 (72%)] Loss: 0.328081
Train Epoch: 1 [14080/19430 (72%)] Loss: 0.302442
Train Epoch: 1 [14240/19430 (73%)] Loss: 0.356441
Train Epoch: 1 [14400/19430 (74%)] Loss: 0.135655
Train Epoch: 1 [14560/19430 (75%)] Loss: 0.568029
Train Epoch: 1 [14720/19430 (76%)] Loss: 0.165823
Train Epoch: 1 [14880/19430 (77%)] Loss: 0.374080
Train Epoch: 1 [15040/19430 (77%)] Loss: 0.077447
Train Epoch: 1 [15200/19430 (78%)] Loss: 0.358019
Train Epoch: 1 [15360/19430 (79%)] Loss: 0.293662
Train Epoch: 1 [15520/19430 (80%)] Loss: 0.163335
Train Epoch: 1 [15680/19430 (81%)] Loss: 0.248658
Train Epoch: 1 [15840/19430 (82%)] Loss: 0.528157
Train Epoch: 1 [16000/19430 (82%)] Loss: 0.208313
Train Epoch: 1 [16160/19430 (83%)] Loss: 0.531372
Train Epoch: 1 [16320/19430 (84%)] Loss: 0.065432
Train Epoch: 1 [16480/19430 (85%)] Loss: 0.178567
Train Epoch: 1 [16640/19430 (86%)] Loss: 0.125679
Train Epoch: 1 [16800/19430 (86%)] Loss: 0.274229
Train Epoch: 1 [16960/19430 (87%)] Loss: 0.136196
Train Epoch: 1 [17120/19430 (88%)] Loss: 0.399171
Train Epoch: 1 [17280/19430 (89%)] Loss: 0.312599
Train Epoch: 1 [17440/19430 (90%)] Loss: 0.203401
Train Epoch: 1 [17600/19430 (91%)] Loss: 0.122040
Train Epoch: 1 [17760/19430 (91%)] Loss: 0.313681
Train Epoch: 1 [17920/19430 (92%)] Loss: 0.064541
Train Epoch: 1 [18080/19430 (93%)] Loss: 0.269304
Train Epoch: 1 [18240/19430 (94%)] Loss: 0.297199
Train Epoch: 1 [18400/19430 (95%)] Loss: 0.513388
Train Epoch: 1 [18560/19430 (96%)] Loss: 0.443021
Train Epoch: 1 [18720/19430 (96%)] Loss: 0.104644
Train Epoch: 1 [18880/19430 (97%)] Loss: 0.253210
Train Epoch: 1 [19040/19430 (98%)] Loss: 0.119658
Train Epoch: 1 [19200/19430 (99%)] Loss: 0.230445
Train Epoch: 1 [19360/19430 (100%)] Loss: 0.462181
    epoch          : 1
    Train_loss     : 0.48190013321092057
    Train_accuracy : 0.842516447368421
    Train_f1_score : 0.8425164818763733
    Val_loss       : 0.2439259927829399
    Val_accuracy   : 0.9168198529411765
    Val_f1_score   : 0.9168198704719543
Warning: Metric 'val_loss' is not found. Model performance monitoring is disabled.
Train Epoch: 2 [0/19430 (0%)] Loss: 0.127520
Train Epoch: 2 [160/19430 (1%)] Loss: 0.146842
Train Epoch: 2 [320/19430 (2%)] Loss: 0.280482
Train Epoch: 2 [480/19430 (2%)] Loss: 0.185266
Train Epoch: 2 [640/19430 (3%)] Loss: 0.145096
Train Epoch: 2 [800/19430 (4%)] Loss: 0.281125
Train Epoch: 2 [960/19430 (5%)] Loss: 0.474398
Train Epoch: 2 [1120/19430 (6%)] Loss: 0.313541
Train Epoch: 2 [1280/19430 (7%)] Loss: 0.113220
Train Epoch: 2 [1440/19430 (7%)] Loss: 0.181966
Train Epoch: 2 [1600/19430 (8%)] Loss: 0.234602
Train Epoch: 2 [1760/19430 (9%)] Loss: 0.354022
Train Epoch: 2 [1920/19430 (10%)] Loss: 0.257700
Train Epoch: 2 [2080/19430 (11%)] Loss: 0.064694
Train Epoch: 2 [2240/19430 (12%)] Loss: 0.176749
Train Epoch: 2 [2400/19430 (12%)] Loss: 0.081742
Train Epoch: 2 [2560/19430 (13%)] Loss: 0.298602
Train Epoch: 2 [2720/19430 (14%)] Loss: 0.073010
Train Epoch: 2 [2880/19430 (15%)] Loss: 0.038108
Train Epoch: 2 [3040/19430 (16%)] Loss: 0.030809
Train Epoch: 2 [3200/19430 (16%)] Loss: 0.460670
Train Epoch: 2 [3360/19430 (17%)] Loss: 0.088025
Train Epoch: 2 [3520/19430 (18%)] Loss: 0.220602
Train Epoch: 2 [3680/19430 (19%)] Loss: 0.209363
Train Epoch: 2 [3840/19430 (20%)] Loss: 0.162537
Train Epoch: 2 [4000/19430 (21%)] Loss: 0.380071
Train Epoch: 2 [4160/19430 (21%)] Loss: 0.383453
Train Epoch: 2 [4320/19430 (22%)] Loss: 0.018524
Train Epoch: 2 [4480/19430 (23%)] Loss: 0.159108
Train Epoch: 2 [4640/19430 (24%)] Loss: 0.140163
Train Epoch: 2 [4800/19430 (25%)] Loss: 0.214556
Train Epoch: 2 [4960/19430 (26%)] Loss: 0.100488
Train Epoch: 2 [5120/19430 (26%)] Loss: 0.053600
Train Epoch: 2 [5280/19430 (27%)] Loss: 0.178907
Train Epoch: 2 [5440/19430 (28%)] Loss: 0.128819
Train Epoch: 2 [5600/19430 (29%)] Loss: 0.055392
Train Epoch: 2 [5760/19430 (30%)] Loss: 0.127522
Train Epoch: 2 [5920/19430 (30%)] Loss: 0.304695
Train Epoch: 2 [6080/19430 (31%)] Loss: 0.256394
Train Epoch: 2 [6240/19430 (32%)] Loss: 0.386608
Train Epoch: 2 [6400/19430 (33%)] Loss: 0.128926
Train Epoch: 2 [6560/19430 (34%)] Loss: 0.352056
Train Epoch: 2 [6720/19430 (35%)] Loss: 0.289442
Train Epoch: 2 [6880/19430 (35%)] Loss: 0.083127
Train Epoch: 2 [7040/19430 (36%)] Loss: 0.056881
Train Epoch: 2 [7200/19430 (37%)] Loss: 0.096989
Train Epoch: 2 [7360/19430 (38%)] Loss: 0.360469
Train Epoch: 2 [7520/19430 (39%)] Loss: 0.031601
Train Epoch: 2 [7680/19430 (40%)] Loss: 0.203846
Train Epoch: 2 [7840/19430 (40%)] Loss: 0.253802
Train Epoch: 2 [8000/19430 (41%)] Loss: 0.094342
Train Epoch: 2 [8160/19430 (42%)] Loss: 0.065770
Train Epoch: 2 [8320/19430 (43%)] Loss: 0.277620
Train Epoch: 2 [8480/19430 (44%)] Loss: 0.098350
Train Epoch: 2 [8640/19430 (44%)] Loss: 0.133286
Train Epoch: 2 [8800/19430 (45%)] Loss: 0.205024
Train Epoch: 2 [8960/19430 (46%)] Loss: 0.131701
Train Epoch: 2 [9120/19430 (47%)] Loss: 0.355298
Train Epoch: 2 [9280/19430 (48%)] Loss: 0.254604
Train Epoch: 2 [9440/19430 (49%)] Loss: 0.120309
Train Epoch: 2 [9600/19430 (49%)] Loss: 0.142307
Train Epoch: 2 [9760/19430 (50%)] Loss: 0.159853
Train Epoch: 2 [9920/19430 (51%)] Loss: 0.072064
Train Epoch: 2 [10080/19430 (52%)] Loss: 0.078023
Train Epoch: 2 [10240/19430 (53%)] Loss: 0.065496
Train Epoch: 2 [10400/19430 (54%)] Loss: 0.347631
Train Epoch: 2 [10560/19430 (54%)] Loss: 0.367654
Train Epoch: 2 [10720/19430 (55%)] Loss: 0.226074
Train Epoch: 2 [10880/19430 (56%)] Loss: 0.110552
Train Epoch: 2 [11040/19430 (57%)] Loss: 0.071155
Train Epoch: 2 [11200/19430 (58%)] Loss: 0.024259
Train Epoch: 2 [11360/19430 (58%)] Loss: 0.066488
Train Epoch: 2 [11520/19430 (59%)] Loss: 0.057431
Train Epoch: 2 [11680/19430 (60%)] Loss: 0.152534
Train Epoch: 2 [11840/19430 (61%)] Loss: 0.064544
Train Epoch: 2 [12000/19430 (62%)] Loss: 0.093479
Train Epoch: 2 [12160/19430 (63%)] Loss: 0.088435
Train Epoch: 2 [12320/19430 (63%)] Loss: 0.169604
Train Epoch: 2 [12480/19430 (64%)] Loss: 0.079721
Train Epoch: 2 [12640/19430 (65%)] Loss: 0.039969
Train Epoch: 2 [12800/19430 (66%)] Loss: 0.032704
Train Epoch: 2 [12960/19430 (67%)] Loss: 0.032961
Train Epoch: 2 [13120/19430 (68%)] Loss: 0.183779
Train Epoch: 2 [13280/19430 (68%)] Loss: 0.071847
Train Epoch: 2 [13440/19430 (69%)] Loss: 0.028100
Train Epoch: 2 [13600/19430 (70%)] Loss: 0.285891
Train Epoch: 2 [13760/19430 (71%)] Loss: 0.097826
Train Epoch: 2 [13920/19430 (72%)] Loss: 0.095857
Train Epoch: 2 [14080/19430 (72%)] Loss: 0.089136
Train Epoch: 2 [14240/19430 (73%)] Loss: 0.075574
Train Epoch: 2 [14400/19430 (74%)] Loss: 0.053797
Train Epoch: 2 [14560/19430 (75%)] Loss: 0.163634
Train Epoch: 2 [14720/19430 (76%)] Loss: 0.417934
Train Epoch: 2 [14880/19430 (77%)] Loss: 0.099380
Train Epoch: 2 [15040/19430 (77%)] Loss: 0.454149
Train Epoch: 2 [15200/19430 (78%)] Loss: 0.105091
Train Epoch: 2 [15360/19430 (79%)] Loss: 0.475945
Train Epoch: 2 [15520/19430 (80%)] Loss: 0.153239
Train Epoch: 2 [15680/19430 (81%)] Loss: 0.294029
Train Epoch: 2 [15840/19430 (82%)] Loss: 0.087407
Train Epoch: 2 [16000/19430 (82%)] Loss: 0.178977
Train Epoch: 2 [16160/19430 (83%)] Loss: 0.213069
Train Epoch: 2 [16320/19430 (84%)] Loss: 0.018246
Train Epoch: 2 [16480/19430 (85%)] Loss: 0.070490
Train Epoch: 2 [16640/19430 (86%)] Loss: 0.017967
Train Epoch: 2 [16800/19430 (86%)] Loss: 0.059024
Train Epoch: 2 [16960/19430 (87%)] Loss: 0.328527
Train Epoch: 2 [17120/19430 (88%)] Loss: 0.276121
Train Epoch: 2 [17280/19430 (89%)] Loss: 0.100883
Train Epoch: 2 [17440/19430 (90%)] Loss: 0.021883
Train Epoch: 2 [17600/19430 (91%)] Loss: 0.297145
Train Epoch: 2 [17760/19430 (91%)] Loss: 0.343710
Train Epoch: 2 [17920/19430 (92%)] Loss: 0.212211
Train Epoch: 2 [18080/19430 (93%)] Loss: 0.086476
Train Epoch: 2 [18240/19430 (94%)] Loss: 0.053974
Train Epoch: 2 [18400/19430 (95%)] Loss: 0.137630
Train Epoch: 2 [18560/19430 (96%)] Loss: 0.201474
Train Epoch: 2 [18720/19430 (96%)] Loss: 0.807226
Train Epoch: 2 [18880/19430 (97%)] Loss: 0.226535
Train Epoch: 2 [19040/19430 (98%)] Loss: 0.109975
Train Epoch: 2 [19200/19430 (99%)] Loss: 0.037868
Train Epoch: 2 [19360/19430 (100%)] Loss: 0.037970
    epoch          : 2
    Train_loss     : 0.1604252322102088
    Train_accuracy : 0.9491330866228069
    Train_f1_score : 0.9491330981254578
    Val_loss       : 0.22567685078555608
    Val_accuracy   : 0.9370404411764706
    Val_f1_score   : 0.9370404481887817
Saving checkpoint: saved/models/efficientnet-b7-pretrained/1028_095732/checkpoint-epoch2.pth ...
Train Epoch: 3 [0/19430 (0%)] Loss: 0.239215
Train Epoch: 3 [160/19430 (1%)] Loss: 0.099918
Train Epoch: 3 [320/19430 (2%)] Loss: 0.055804
Train Epoch: 3 [480/19430 (2%)] Loss: 0.083205
Train Epoch: 3 [640/19430 (3%)] Loss: 0.051840
Train Epoch: 3 [800/19430 (4%)] Loss: 0.367225
Train Epoch: 3 [960/19430 (5%)] Loss: 0.189558
Train Epoch: 3 [1120/19430 (6%)] Loss: 0.020071
Train Epoch: 3 [1280/19430 (7%)] Loss: 0.019499
Train Epoch: 3 [1440/19430 (7%)] Loss: 0.041142
Train Epoch: 3 [1600/19430 (8%)] Loss: 0.097349
Train Epoch: 3 [1760/19430 (9%)] Loss: 0.044766
Train Epoch: 3 [1920/19430 (10%)] Loss: 0.046445
Train Epoch: 3 [2080/19430 (11%)] Loss: 0.311616
Train Epoch: 3 [2240/19430 (12%)] Loss: 0.236573
Train Epoch: 3 [2400/19430 (12%)] Loss: 0.089393
Train Epoch: 3 [2560/19430 (13%)] Loss: 0.037181
Train Epoch: 3 [2720/19430 (14%)] Loss: 0.067491
Train Epoch: 3 [2880/19430 (15%)] Loss: 0.247489
Train Epoch: 3 [3040/19430 (16%)] Loss: 0.048407
Train Epoch: 3 [3200/19430 (16%)] Loss: 0.066830
Train Epoch: 3 [3360/19430 (17%)] Loss: 0.564426
Train Epoch: 3 [3520/19430 (18%)] Loss: 0.052187
Train Epoch: 3 [3680/19430 (19%)] Loss: 0.014064
Train Epoch: 3 [3840/19430 (20%)] Loss: 0.067803
Train Epoch: 3 [4000/19430 (21%)] Loss: 0.237301
Train Epoch: 3 [4160/19430 (21%)] Loss: 0.247766
Train Epoch: 3 [4320/19430 (22%)] Loss: 0.091452
Train Epoch: 3 [4480/19430 (23%)] Loss: 0.032218
Train Epoch: 3 [4640/19430 (24%)] Loss: 0.099629
Train Epoch: 3 [4800/19430 (25%)] Loss: 0.298522
Train Epoch: 3 [4960/19430 (26%)] Loss: 0.103357
Train Epoch: 3 [5120/19430 (26%)] Loss: 0.033557
Train Epoch: 3 [5280/19430 (27%)] Loss: 0.714647
Train Epoch: 3 [5440/19430 (28%)] Loss: 0.092219
Train Epoch: 3 [5600/19430 (29%)] Loss: 0.222615
Train Epoch: 3 [5760/19430 (30%)] Loss: 0.041861
Train Epoch: 3 [5920/19430 (30%)] Loss: 0.069067
Train Epoch: 3 [6080/19430 (31%)] Loss: 0.011973
Train Epoch: 3 [6240/19430 (32%)] Loss: 0.107917
Train Epoch: 3 [6400/19430 (33%)] Loss: 0.071178
Train Epoch: 3 [6560/19430 (34%)] Loss: 0.023145
Train Epoch: 3 [6720/19430 (35%)] Loss: 0.146504
Train Epoch: 3 [6880/19430 (35%)] Loss: 0.057434
Train Epoch: 3 [7040/19430 (36%)] Loss: 0.117772
Train Epoch: 3 [7200/19430 (37%)] Loss: 0.400444
Train Epoch: 3 [7360/19430 (38%)] Loss: 0.040086
Train Epoch: 3 [7520/19430 (39%)] Loss: 0.045391
Train Epoch: 3 [7680/19430 (40%)] Loss: 0.021725
Train Epoch: 3 [7840/19430 (40%)] Loss: 0.094754
Train Epoch: 3 [8000/19430 (41%)] Loss: 0.056080
Train Epoch: 3 [8160/19430 (42%)] Loss: 0.046113
Train Epoch: 3 [8320/19430 (43%)] Loss: 0.180633
Train Epoch: 3 [8480/19430 (44%)] Loss: 0.035976
Train Epoch: 3 [8640/19430 (44%)] Loss: 0.039768
Train Epoch: 3 [8800/19430 (45%)] Loss: 0.161089
Train Epoch: 3 [8960/19430 (46%)] Loss: 0.074880
Train Epoch: 3 [9120/19430 (47%)] Loss: 0.267664
Train Epoch: 3 [9280/19430 (48%)] Loss: 0.045390
Train Epoch: 3 [9440/19430 (49%)] Loss: 0.060832
Train Epoch: 3 [9600/19430 (49%)] Loss: 0.278444
Train Epoch: 3 [9760/19430 (50%)] Loss: 0.099430
Train Epoch: 3 [9920/19430 (51%)] Loss: 0.138694
Train Epoch: 3 [10080/19430 (52%)] Loss: 0.011155
Train Epoch: 3 [10240/19430 (53%)] Loss: 0.045928
Train Epoch: 3 [10400/19430 (54%)] Loss: 0.166854
Train Epoch: 3 [10560/19430 (54%)] Loss: 0.050318
Train Epoch: 3 [10720/19430 (55%)] Loss: 0.046752
Train Epoch: 3 [10880/19430 (56%)] Loss: 0.042306
Train Epoch: 3 [11040/19430 (57%)] Loss: 0.109243
Train Epoch: 3 [11200/19430 (58%)] Loss: 0.181044
Train Epoch: 3 [11360/19430 (58%)] Loss: 0.026096
Train Epoch: 3 [11520/19430 (59%)] Loss: 0.029183
Train Epoch: 3 [11680/19430 (60%)] Loss: 0.005362
Train Epoch: 3 [11840/19430 (61%)] Loss: 0.080692
Train Epoch: 3 [12000/19430 (62%)] Loss: 0.228708
Train Epoch: 3 [12160/19430 (63%)] Loss: 0.035409
Train Epoch: 3 [12320/19430 (63%)] Loss: 0.018612
Train Epoch: 3 [12480/19430 (64%)] Loss: 0.231348
Train Epoch: 3 [12640/19430 (65%)] Loss: 0.458294
Train Epoch: 3 [12800/19430 (66%)] Loss: 0.027249
Train Epoch: 3 [12960/19430 (67%)] Loss: 0.263093
Train Epoch: 3 [13120/19430 (68%)] Loss: 0.063492
Train Epoch: 3 [13280/19430 (68%)] Loss: 0.226193
Train Epoch: 3 [13440/19430 (69%)] Loss: 0.132042
Train Epoch: 3 [13600/19430 (70%)] Loss: 0.066603
Train Epoch: 3 [13760/19430 (71%)] Loss: 0.074351
Train Epoch: 3 [13920/19430 (72%)] Loss: 0.013775
Train Epoch: 3 [14080/19430 (72%)] Loss: 0.041381
Train Epoch: 3 [14240/19430 (73%)] Loss: 0.013236
Train Epoch: 3 [14400/19430 (74%)] Loss: 0.082395
Train Epoch: 3 [14560/19430 (75%)] Loss: 0.009349
Train Epoch: 3 [14720/19430 (76%)] Loss: 0.019828
Train Epoch: 3 [14880/19430 (77%)] Loss: 0.024735
Train Epoch: 3 [15040/19430 (77%)] Loss: 0.067822
Train Epoch: 3 [15200/19430 (78%)] Loss: 0.028158
Train Epoch: 3 [15360/19430 (79%)] Loss: 0.067889
Train Epoch: 3 [15520/19430 (80%)] Loss: 0.035855
Train Epoch: 3 [15680/19430 (81%)] Loss: 0.431646
Train Epoch: 3 [15840/19430 (82%)] Loss: 0.063136
Train Epoch: 3 [16000/19430 (82%)] Loss: 0.005371
Train Epoch: 3 [16160/19430 (83%)] Loss: 0.149924
Train Epoch: 3 [16320/19430 (84%)] Loss: 0.068545
Train Epoch: 3 [16480/19430 (85%)] Loss: 0.022477
Train Epoch: 3 [16640/19430 (86%)] Loss: 0.285820
Train Epoch: 3 [16800/19430 (86%)] Loss: 0.012457
Train Epoch: 3 [16960/19430 (87%)] Loss: 0.074475
Train Epoch: 3 [17120/19430 (88%)] Loss: 0.224183
Train Epoch: 3 [17280/19430 (89%)] Loss: 0.024615
Train Epoch: 3 [17440/19430 (90%)] Loss: 0.190841
Train Epoch: 3 [17600/19430 (91%)] Loss: 0.208400
Train Epoch: 3 [17760/19430 (91%)] Loss: 0.246895
Train Epoch: 3 [17920/19430 (92%)] Loss: 0.089675
Train Epoch: 3 [18080/19430 (93%)] Loss: 0.170540
Train Epoch: 3 [18240/19430 (94%)] Loss: 0.042060
Train Epoch: 3 [18400/19430 (95%)] Loss: 0.066650
Train Epoch: 3 [18560/19430 (96%)] Loss: 0.152098
Train Epoch: 3 [18720/19430 (96%)] Loss: 0.070364
Train Epoch: 3 [18880/19430 (97%)] Loss: 0.026926
Train Epoch: 3 [19040/19430 (98%)] Loss: 0.007923
Train Epoch: 3 [19200/19430 (99%)] Loss: 0.026225
Train Epoch: 3 [19360/19430 (100%)] Loss: 0.005691
    epoch          : 3
    Train_loss     : 0.10970107401264709
    Train_accuracy : 0.9654947916666667
    Train_f1_score : 0.9654947519302368
    Val_loss       : 0.08986495153786724
    Val_accuracy   : 0.9750525210084033
    Val_f1_score   : 0.975052535533905
Train Epoch: 4 [0/19430 (0%)] Loss: 0.007192
Train Epoch: 4 [160/19430 (1%)] Loss: 0.058088
Train Epoch: 4 [320/19430 (2%)] Loss: 0.003004
Train Epoch: 4 [480/19430 (2%)] Loss: 0.086966
Train Epoch: 4 [640/19430 (3%)] Loss: 0.028684
Train Epoch: 4 [800/19430 (4%)] Loss: 0.133963
Train Epoch: 4 [960/19430 (5%)] Loss: 0.354594
Train Epoch: 4 [1120/19430 (6%)] Loss: 0.025478
Train Epoch: 4 [1280/19430 (7%)] Loss: 0.159780
Train Epoch: 4 [1440/19430 (7%)] Loss: 0.026244
Train Epoch: 4 [1600/19430 (8%)] Loss: 0.132368
Train Epoch: 4 [1760/19430 (9%)] Loss: 0.058916
Train Epoch: 4 [1920/19430 (10%)] Loss: 0.014434
Train Epoch: 4 [2080/19430 (11%)] Loss: 0.022052
Train Epoch: 4 [2240/19430 (12%)] Loss: 0.007186
Train Epoch: 4 [2400/19430 (12%)] Loss: 0.011977
Train Epoch: 4 [2560/19430 (13%)] Loss: 0.008503
Train Epoch: 4 [2720/19430 (14%)] Loss: 0.010570
Train Epoch: 4 [2880/19430 (15%)] Loss: 0.023449
Train Epoch: 4 [3040/19430 (16%)] Loss: 0.207628
Train Epoch: 4 [3200/19430 (16%)] Loss: 0.007859
Train Epoch: 4 [3360/19430 (17%)] Loss: 0.020527
Train Epoch: 4 [3520/19430 (18%)] Loss: 0.151574
Train Epoch: 4 [3680/19430 (19%)] Loss: 0.147977
Train Epoch: 4 [3840/19430 (20%)] Loss: 0.004347
Train Epoch: 4 [4000/19430 (21%)] Loss: 0.190630
Train Epoch: 4 [4160/19430 (21%)] Loss: 0.015534
Train Epoch: 4 [4320/19430 (22%)] Loss: 0.013329
Train Epoch: 4 [4480/19430 (23%)] Loss: 0.002303
Train Epoch: 4 [4640/19430 (24%)] Loss: 0.116563
Train Epoch: 4 [4800/19430 (25%)] Loss: 0.181385
Train Epoch: 4 [4960/19430 (26%)] Loss: 0.002963
Train Epoch: 4 [5120/19430 (26%)] Loss: 0.034121
Train Epoch: 4 [5280/19430 (27%)] Loss: 0.002613
Train Epoch: 4 [5440/19430 (28%)] Loss: 0.017906
Train Epoch: 4 [5600/19430 (29%)] Loss: 0.141036
Train Epoch: 4 [5760/19430 (30%)] Loss: 0.065283
Train Epoch: 4 [5920/19430 (30%)] Loss: 0.011743
Train Epoch: 4 [6080/19430 (31%)] Loss: 0.014785
Train Epoch: 4 [6240/19430 (32%)] Loss: 0.017165
Train Epoch: 4 [6400/19430 (33%)] Loss: 0.004915
Train Epoch: 4 [6560/19430 (34%)] Loss: 0.006193
Train Epoch: 4 [6720/19430 (35%)] Loss: 0.013063
Train Epoch: 4 [6880/19430 (35%)] Loss: 0.005844
Train Epoch: 4 [7040/19430 (36%)] Loss: 0.116797
Train Epoch: 4 [7200/19430 (37%)] Loss: 0.011883
Train Epoch: 4 [7360/19430 (38%)] Loss: 0.039745
Train Epoch: 4 [7520/19430 (39%)] Loss: 0.048136
Train Epoch: 4 [7680/19430 (40%)] Loss: 0.104271
Train Epoch: 4 [7840/19430 (40%)] Loss: 0.033495
Train Epoch: 4 [8000/19430 (41%)] Loss: 0.070818
Train Epoch: 4 [8160/19430 (42%)] Loss: 0.005567
Train Epoch: 4 [8320/19430 (43%)] Loss: 0.012896
Train Epoch: 4 [8480/19430 (44%)] Loss: 0.077674
Train Epoch: 4 [8640/19430 (44%)] Loss: 0.024107
Train Epoch: 4 [8800/19430 (45%)] Loss: 0.007524
Train Epoch: 4 [8960/19430 (46%)] Loss: 0.008656
Train Epoch: 4 [9120/19430 (47%)] Loss: 0.119713
Train Epoch: 4 [9280/19430 (48%)] Loss: 0.078859
Train Epoch: 4 [9440/19430 (49%)] Loss: 0.006985
Train Epoch: 4 [9600/19430 (49%)] Loss: 0.048544
Train Epoch: 4 [9760/19430 (50%)] Loss: 0.026369
Train Epoch: 4 [9920/19430 (51%)] Loss: 0.114517
Train Epoch: 4 [10080/19430 (52%)] Loss: 0.028350
Train Epoch: 4 [10240/19430 (53%)] Loss: 0.123323
Train Epoch: 4 [10400/19430 (54%)] Loss: 0.015793
Train Epoch: 4 [10560/19430 (54%)] Loss: 0.003203
Train Epoch: 4 [10720/19430 (55%)] Loss: 0.143769
Train Epoch: 4 [10880/19430 (56%)] Loss: 0.010584
Train Epoch: 4 [11040/19430 (57%)] Loss: 0.003687
Train Epoch: 4 [11200/19430 (58%)] Loss: 0.065445
Train Epoch: 4 [11360/19430 (58%)] Loss: 0.150908
Train Epoch: 4 [11520/19430 (59%)] Loss: 0.037186
Train Epoch: 4 [11680/19430 (60%)] Loss: 0.016004
Train Epoch: 4 [11840/19430 (61%)] Loss: 0.079502
Train Epoch: 4 [12000/19430 (62%)] Loss: 0.004866
Train Epoch: 4 [12160/19430 (63%)] Loss: 0.013074
Train Epoch: 4 [12320/19430 (63%)] Loss: 0.003472
Train Epoch: 4 [12480/19430 (64%)] Loss: 0.020085
Train Epoch: 4 [12640/19430 (65%)] Loss: 0.046475
Train Epoch: 4 [12800/19430 (66%)] Loss: 0.071267
Train Epoch: 4 [12960/19430 (67%)] Loss: 0.006153
Train Epoch: 4 [13120/19430 (68%)] Loss: 0.007468
Train Epoch: 4 [13280/19430 (68%)] Loss: 0.073138
Train Epoch: 4 [13440/19430 (69%)] Loss: 0.052496
Train Epoch: 4 [13600/19430 (70%)] Loss: 0.016041
Train Epoch: 4 [13760/19430 (71%)] Loss: 0.166150
Train Epoch: 4 [13920/19430 (72%)] Loss: 0.012446
Train Epoch: 4 [14080/19430 (72%)] Loss: 0.260542
Train Epoch: 4 [14240/19430 (73%)] Loss: 0.371574
Train Epoch: 4 [14400/19430 (74%)] Loss: 0.009336
Train Epoch: 4 [14560/19430 (75%)] Loss: 0.138191
Train Epoch: 4 [14720/19430 (76%)] Loss: 0.031409
Train Epoch: 4 [14880/19430 (77%)] Loss: 0.118578
Train Epoch: 4 [15040/19430 (77%)] Loss: 0.153706
Train Epoch: 4 [15200/19430 (78%)] Loss: 0.018380
Train Epoch: 4 [15360/19430 (79%)] Loss: 0.013898
Train Epoch: 4 [15520/19430 (80%)] Loss: 0.007597
Train Epoch: 4 [15680/19430 (81%)] Loss: 0.002985
Train Epoch: 4 [15840/19430 (82%)] Loss: 0.048608
Train Epoch: 4 [16000/19430 (82%)] Loss: 0.035662
Train Epoch: 4 [16160/19430 (83%)] Loss: 0.030073
Train Epoch: 4 [16320/19430 (84%)] Loss: 0.020860
Train Epoch: 4 [16480/19430 (85%)] Loss: 0.026816
Train Epoch: 4 [16640/19430 (86%)] Loss: 0.009920
Train Epoch: 4 [16800/19430 (86%)] Loss: 0.078914
Train Epoch: 4 [16960/19430 (87%)] Loss: 0.051722
Train Epoch: 4 [17120/19430 (88%)] Loss: 0.306486
Train Epoch: 4 [17280/19430 (89%)] Loss: 0.002404
Train Epoch: 4 [17440/19430 (90%)] Loss: 0.027689
Train Epoch: 4 [17600/19430 (91%)] Loss: 0.269936
Train Epoch: 4 [17760/19430 (91%)] Loss: 0.020011
Train Epoch: 4 [17920/19430 (92%)] Loss: 0.002335
Train Epoch: 4 [18080/19430 (93%)] Loss: 0.019632
Train Epoch: 4 [18240/19430 (94%)] Loss: 0.009845
Train Epoch: 4 [18400/19430 (95%)] Loss: 0.063442
Train Epoch: 4 [18560/19430 (96%)] Loss: 0.035022
Train Epoch: 4 [18720/19430 (96%)] Loss: 0.249484
Train Epoch: 4 [18880/19430 (97%)] Loss: 0.004696
Train Epoch: 4 [19040/19430 (98%)] Loss: 0.006671
Train Epoch: 4 [19200/19430 (99%)] Loss: 0.025871
Train Epoch: 4 [19360/19430 (100%)] Loss: 0.002668
    epoch          : 4
    Train_loss     : 0.053382685482287535
    Train_accuracy : 0.9833984375
    Train_f1_score : 0.9833984375
    Val_loss       : 0.05583648589013405
    Val_accuracy   : 0.984375
    Val_f1_score   : 0.984375
Saving checkpoint: saved/models/efficientnet-b7-pretrained/1028_095732/checkpoint-epoch4.pth ...
Train Epoch: 5 [0/19430 (0%)] Loss: 0.014405
Train Epoch: 5 [160/19430 (1%)] Loss: 0.001498
Train Epoch: 5 [320/19430 (2%)] Loss: 0.006192
Train Epoch: 5 [480/19430 (2%)] Loss: 0.007805
Train Epoch: 5 [640/19430 (3%)] Loss: 0.004497
Train Epoch: 5 [800/19430 (4%)] Loss: 0.006552
Train Epoch: 5 [960/19430 (5%)] Loss: 0.014116
Train Epoch: 5 [1120/19430 (6%)] Loss: 0.050679
Train Epoch: 5 [1280/19430 (7%)] Loss: 0.027748
Train Epoch: 5 [1440/19430 (7%)] Loss: 0.007117
Train Epoch: 5 [1600/19430 (8%)] Loss: 0.002167
Train Epoch: 5 [1760/19430 (9%)] Loss: 0.001482
Train Epoch: 5 [1920/19430 (10%)] Loss: 0.002094
Train Epoch: 5 [2080/19430 (11%)] Loss: 0.001444
Train Epoch: 5 [2240/19430 (12%)] Loss: 0.124994
Train Epoch: 5 [2400/19430 (12%)] Loss: 0.010703
Train Epoch: 5 [2560/19430 (13%)] Loss: 0.012906
Train Epoch: 5 [2720/19430 (14%)] Loss: 0.023049
Train Epoch: 5 [2880/19430 (15%)] Loss: 0.001885
Train Epoch: 5 [3040/19430 (16%)] Loss: 0.039192
Train Epoch: 5 [3200/19430 (16%)] Loss: 0.005680
Train Epoch: 5 [3360/19430 (17%)] Loss: 0.012706
Train Epoch: 5 [3520/19430 (18%)] Loss: 0.121858
Train Epoch: 5 [3680/19430 (19%)] Loss: 0.036726
Train Epoch: 5 [3840/19430 (20%)] Loss: 0.055830
Train Epoch: 5 [4000/19430 (21%)] Loss: 0.104012
Train Epoch: 5 [4160/19430 (21%)] Loss: 0.010387
Train Epoch: 5 [4320/19430 (22%)] Loss: 0.444663
Train Epoch: 5 [4480/19430 (23%)] Loss: 0.002934
Train Epoch: 5 [4640/19430 (24%)] Loss: 0.002899
Train Epoch: 5 [4800/19430 (25%)] Loss: 0.054066
Train Epoch: 5 [4960/19430 (26%)] Loss: 0.007764
Train Epoch: 5 [5120/19430 (26%)] Loss: 0.003231
Train Epoch: 5 [5280/19430 (27%)] Loss: 0.146841
Train Epoch: 5 [5440/19430 (28%)] Loss: 0.003576
Train Epoch: 5 [5600/19430 (29%)] Loss: 0.004654
Train Epoch: 5 [5760/19430 (30%)] Loss: 0.078504
Train Epoch: 5 [5920/19430 (30%)] Loss: 0.069549
Train Epoch: 5 [6080/19430 (31%)] Loss: 0.001732
Train Epoch: 5 [6240/19430 (32%)] Loss: 0.079191
Train Epoch: 5 [6400/19430 (33%)] Loss: 0.009479
Train Epoch: 5 [6560/19430 (34%)] Loss: 0.152750
Train Epoch: 5 [6720/19430 (35%)] Loss: 0.236655
Train Epoch: 5 [6880/19430 (35%)] Loss: 0.045101
Train Epoch: 5 [7040/19430 (36%)] Loss: 0.029317
Train Epoch: 5 [7200/19430 (37%)] Loss: 0.507232
Train Epoch: 5 [7360/19430 (38%)] Loss: 0.063927
Train Epoch: 5 [7520/19430 (39%)] Loss: 0.005228
Train Epoch: 5 [7680/19430 (40%)] Loss: 0.006704
Train Epoch: 5 [7840/19430 (40%)] Loss: 0.004693
Train Epoch: 5 [8000/19430 (41%)] Loss: 0.043958
Train Epoch: 5 [8160/19430 (42%)] Loss: 0.018098
Train Epoch: 5 [8320/19430 (43%)] Loss: 0.006276
Train Epoch: 5 [8480/19430 (44%)] Loss: 0.025784
Train Epoch: 5 [8640/19430 (44%)] Loss: 0.033948
Train Epoch: 5 [8800/19430 (45%)] Loss: 0.007430
Train Epoch: 5 [8960/19430 (46%)] Loss: 0.007909
Train Epoch: 5 [9120/19430 (47%)] Loss: 0.009831
Train Epoch: 5 [9280/19430 (48%)] Loss: 0.006127
Train Epoch: 5 [9440/19430 (49%)] Loss: 0.004588
Train Epoch: 5 [9600/19430 (49%)] Loss: 0.008614
Train Epoch: 5 [9760/19430 (50%)] Loss: 0.005922
Train Epoch: 5 [9920/19430 (51%)] Loss: 0.018498
Train Epoch: 5 [10080/19430 (52%)] Loss: 0.003478
Train Epoch: 5 [10240/19430 (53%)] Loss: 0.063388
Train Epoch: 5 [10400/19430 (54%)] Loss: 0.002407
Train Epoch: 5 [10560/19430 (54%)] Loss: 0.006537
Train Epoch: 5 [10720/19430 (55%)] Loss: 0.037036
Train Epoch: 5 [10880/19430 (56%)] Loss: 0.253234
Train Epoch: 5 [11040/19430 (57%)] Loss: 0.003705
Train Epoch: 5 [11200/19430 (58%)] Loss: 0.135334
Train Epoch: 5 [11360/19430 (58%)] Loss: 0.058602
Train Epoch: 5 [11520/19430 (59%)] Loss: 0.107887
Train Epoch: 5 [11680/19430 (60%)] Loss: 0.005814
Train Epoch: 5 [11840/19430 (61%)] Loss: 0.062918
Train Epoch: 5 [12000/19430 (62%)] Loss: 0.031927
Train Epoch: 5 [12160/19430 (63%)] Loss: 0.016818
Train Epoch: 5 [12320/19430 (63%)] Loss: 0.002876
Train Epoch: 5 [12480/19430 (64%)] Loss: 0.003996
Train Epoch: 5 [12640/19430 (65%)] Loss: 0.114973
Train Epoch: 5 [12800/19430 (66%)] Loss: 0.164674
Train Epoch: 5 [12960/19430 (67%)] Loss: 0.094036
Train Epoch: 5 [13120/19430 (68%)] Loss: 0.004331
Train Epoch: 5 [13280/19430 (68%)] Loss: 0.017276
Train Epoch: 5 [13440/19430 (69%)] Loss: 0.003499
Train Epoch: 5 [13600/19430 (70%)] Loss: 0.009706
Train Epoch: 5 [13760/19430 (71%)] Loss: 0.003672
Train Epoch: 5 [13920/19430 (72%)] Loss: 0.025184
Train Epoch: 5 [14080/19430 (72%)] Loss: 0.145060
Train Epoch: 5 [14240/19430 (73%)] Loss: 0.050361
Train Epoch: 5 [14400/19430 (74%)] Loss: 0.005671
Train Epoch: 5 [14560/19430 (75%)] Loss: 0.009935
Train Epoch: 5 [14720/19430 (76%)] Loss: 0.000750
Train Epoch: 5 [14880/19430 (77%)] Loss: 0.015285
Train Epoch: 5 [15040/19430 (77%)] Loss: 0.064974
Train Epoch: 5 [15200/19430 (78%)] Loss: 0.003249
Train Epoch: 5 [15360/19430 (79%)] Loss: 0.005237
Train Epoch: 5 [15520/19430 (80%)] Loss: 0.383476
Train Epoch: 5 [15680/19430 (81%)] Loss: 0.006724
Train Epoch: 5 [15840/19430 (82%)] Loss: 0.027518
Train Epoch: 5 [16000/19430 (82%)] Loss: 0.013832
Train Epoch: 5 [16160/19430 (83%)] Loss: 0.003704
Train Epoch: 5 [16320/19430 (84%)] Loss: 0.001807
Train Epoch: 5 [16480/19430 (85%)] Loss: 0.211704
Train Epoch: 5 [16640/19430 (86%)] Loss: 0.012677
Train Epoch: 5 [16800/19430 (86%)] Loss: 0.000844
Train Epoch: 5 [16960/19430 (87%)] Loss: 0.039944
Train Epoch: 5 [17120/19430 (88%)] Loss: 0.012071
Train Epoch: 5 [17280/19430 (89%)] Loss: 0.011034
Train Epoch: 5 [17440/19430 (90%)] Loss: 0.017562
Train Epoch: 5 [17600/19430 (91%)] Loss: 0.008506
Train Epoch: 5 [17760/19430 (91%)] Loss: 0.075089
Train Epoch: 5 [17920/19430 (92%)] Loss: 0.061060
Train Epoch: 5 [18080/19430 (93%)] Loss: 0.006543
Train Epoch: 5 [18240/19430 (94%)] Loss: 0.002082
Train Epoch: 5 [18400/19430 (95%)] Loss: 0.246550
Train Epoch: 5 [18560/19430 (96%)] Loss: 0.013422
Train Epoch: 5 [18720/19430 (96%)] Loss: 0.071502
Train Epoch: 5 [18880/19430 (97%)] Loss: 0.145307
Train Epoch: 5 [19040/19430 (98%)] Loss: 0.035007
Train Epoch: 5 [19200/19430 (99%)] Loss: 0.011840
Train Epoch: 5 [19360/19430 (100%)] Loss: 0.012983
    epoch          : 5
    Train_loss     : 0.04998931546254569
    Train_accuracy : 0.9848889802631579
    Train_f1_score : 0.9848889708518982
    Val_loss       : 0.20347072517239106
    Val_accuracy   : 0.946888130252101
    Val_f1_score   : 0.9468880891799927
Train Epoch: 6 [0/19430 (0%)] Loss: 0.046103
Train Epoch: 6 [160/19430 (1%)] Loss: 0.007646
Train Epoch: 6 [320/19430 (2%)] Loss: 0.001821
Train Epoch: 6 [480/19430 (2%)] Loss: 0.002430
Train Epoch: 6 [640/19430 (3%)] Loss: 0.031860
Train Epoch: 6 [800/19430 (4%)] Loss: 0.029088
Train Epoch: 6 [960/19430 (5%)] Loss: 0.069797
Train Epoch: 6 [1120/19430 (6%)] Loss: 0.013756
Train Epoch: 6 [1280/19430 (7%)] Loss: 0.008129
Train Epoch: 6 [1440/19430 (7%)] Loss: 0.208063
Train Epoch: 6 [1600/19430 (8%)] Loss: 0.035502
Train Epoch: 6 [1760/19430 (9%)] Loss: 0.039568
Train Epoch: 6 [1920/19430 (10%)] Loss: 0.002444
Train Epoch: 6 [2080/19430 (11%)] Loss: 0.018797
Train Epoch: 6 [2240/19430 (12%)] Loss: 0.174489
Train Epoch: 6 [2400/19430 (12%)] Loss: 0.094145
Train Epoch: 6 [2560/19430 (13%)] Loss: 0.011693
Train Epoch: 6 [2720/19430 (14%)] Loss: 0.023903
Train Epoch: 6 [2880/19430 (15%)] Loss: 0.012840
Train Epoch: 6 [3040/19430 (16%)] Loss: 0.001636
Train Epoch: 6 [3200/19430 (16%)] Loss: 0.061274
Train Epoch: 6 [3360/19430 (17%)] Loss: 0.005612
Train Epoch: 6 [3520/19430 (18%)] Loss: 0.008471
Train Epoch: 6 [3680/19430 (19%)] Loss: 0.085976
Train Epoch: 6 [3840/19430 (20%)] Loss: 0.134585
Train Epoch: 6 [4000/19430 (21%)] Loss: 0.003255
Train Epoch: 6 [4160/19430 (21%)] Loss: 0.011260
Train Epoch: 6 [4320/19430 (22%)] Loss: 0.275266
Train Epoch: 6 [4480/19430 (23%)] Loss: 0.005530
Train Epoch: 6 [4640/19430 (24%)] Loss: 0.082148
Train Epoch: 6 [4800/19430 (25%)] Loss: 0.034460
Train Epoch: 6 [4960/19430 (26%)] Loss: 0.020592
Train Epoch: 6 [5120/19430 (26%)] Loss: 0.098159
Train Epoch: 6 [5280/19430 (27%)] Loss: 0.012485
Train Epoch: 6 [5440/19430 (28%)] Loss: 0.063443
Train Epoch: 6 [5600/19430 (29%)] Loss: 0.017032
Train Epoch: 6 [5760/19430 (30%)] Loss: 0.004222
Train Epoch: 6 [5920/19430 (30%)] Loss: 0.002118
Train Epoch: 6 [6080/19430 (31%)] Loss: 0.029022
Train Epoch: 6 [6240/19430 (32%)] Loss: 0.010043
Train Epoch: 6 [6400/19430 (33%)] Loss: 0.063275
Train Epoch: 6 [6560/19430 (34%)] Loss: 0.065899
Train Epoch: 6 [6720/19430 (35%)] Loss: 0.004135
Train Epoch: 6 [6880/19430 (35%)] Loss: 0.017030
Train Epoch: 6 [7040/19430 (36%)] Loss: 0.009502
Train Epoch: 6 [7200/19430 (37%)] Loss: 0.122832
Train Epoch: 6 [7360/19430 (38%)] Loss: 0.021689
Train Epoch: 6 [7520/19430 (39%)] Loss: 0.006787
Train Epoch: 6 [7680/19430 (40%)] Loss: 0.023321
Train Epoch: 6 [7840/19430 (40%)] Loss: 0.013652
Train Epoch: 6 [8000/19430 (41%)] Loss: 0.069234
Train Epoch: 6 [8160/19430 (42%)] Loss: 0.093941
Train Epoch: 6 [8320/19430 (43%)] Loss: 0.003179
Train Epoch: 6 [8480/19430 (44%)] Loss: 0.009098
Train Epoch: 6 [8640/19430 (44%)] Loss: 0.073682
Train Epoch: 6 [8800/19430 (45%)] Loss: 0.044298
Train Epoch: 6 [8960/19430 (46%)] Loss: 0.115966
Train Epoch: 6 [9120/19430 (47%)] Loss: 0.021153
Train Epoch: 6 [9280/19430 (48%)] Loss: 0.072690
Train Epoch: 6 [9440/19430 (49%)] Loss: 0.007111
Train Epoch: 6 [9600/19430 (49%)] Loss: 0.004751
Train Epoch: 6 [9760/19430 (50%)] Loss: 0.001523
Train Epoch: 6 [9920/19430 (51%)] Loss: 0.005558
Train Epoch: 6 [10080/19430 (52%)] Loss: 0.008295
Train Epoch: 6 [10240/19430 (53%)] Loss: 0.020452
Train Epoch: 6 [10400/19430 (54%)] Loss: 0.002251
Train Epoch: 6 [10560/19430 (54%)] Loss: 0.018913
Train Epoch: 6 [10720/19430 (55%)] Loss: 0.007352
Train Epoch: 6 [10880/19430 (56%)] Loss: 0.008050
Train Epoch: 6 [11040/19430 (57%)] Loss: 0.035583
Train Epoch: 6 [11200/19430 (58%)] Loss: 0.001317
Train Epoch: 6 [11360/19430 (58%)] Loss: 0.006545
Train Epoch: 6 [11520/19430 (59%)] Loss: 0.015637
Train Epoch: 6 [11680/19430 (60%)] Loss: 0.003573
Train Epoch: 6 [11840/19430 (61%)] Loss: 0.004273
Train Epoch: 6 [12000/19430 (62%)] Loss: 0.004450
Train Epoch: 6 [12160/19430 (63%)] Loss: 0.019895
Train Epoch: 6 [12320/19430 (63%)] Loss: 0.003894
Train Epoch: 6 [12480/19430 (64%)] Loss: 0.004390
Train Epoch: 6 [12640/19430 (65%)] Loss: 0.003966
Train Epoch: 6 [12800/19430 (66%)] Loss: 0.000902
Train Epoch: 6 [12960/19430 (67%)] Loss: 0.028939
Train Epoch: 6 [13120/19430 (68%)] Loss: 0.001029
Train Epoch: 6 [13280/19430 (68%)] Loss: 0.005126
Train Epoch: 6 [13440/19430 (69%)] Loss: 0.001840
Train Epoch: 6 [13600/19430 (70%)] Loss: 0.007051
Train Epoch: 6 [13760/19430 (71%)] Loss: 0.003643
Train Epoch: 6 [13920/19430 (72%)] Loss: 0.001518
Train Epoch: 6 [14080/19430 (72%)] Loss: 0.008307
Train Epoch: 6 [14240/19430 (73%)] Loss: 0.000616
Train Epoch: 6 [14400/19430 (74%)] Loss: 0.000561
Train Epoch: 6 [14560/19430 (75%)] Loss: 0.019780
Train Epoch: 6 [14720/19430 (76%)] Loss: 0.004180
Train Epoch: 6 [14880/19430 (77%)] Loss: 0.071657
Train Epoch: 6 [15040/19430 (77%)] Loss: 0.005898
Train Epoch: 6 [15200/19430 (78%)] Loss: 0.003209
Train Epoch: 6 [15360/19430 (79%)] Loss: 0.001311
Train Epoch: 6 [15520/19430 (80%)] Loss: 0.015822
Train Epoch: 6 [15680/19430 (81%)] Loss: 0.001941
Train Epoch: 6 [15840/19430 (82%)] Loss: 0.000646
Train Epoch: 6 [16000/19430 (82%)] Loss: 0.000258
Train Epoch: 6 [16160/19430 (83%)] Loss: 0.001832
Train Epoch: 6 [16320/19430 (84%)] Loss: 0.000517
Train Epoch: 6 [16480/19430 (85%)] Loss: 0.001650
Train Epoch: 6 [16640/19430 (86%)] Loss: 0.004089
Train Epoch: 6 [16800/19430 (86%)] Loss: 0.000399
Train Epoch: 6 [16960/19430 (87%)] Loss: 0.009416
Train Epoch: 6 [17120/19430 (88%)] Loss: 0.027713
Train Epoch: 6 [17280/19430 (89%)] Loss: 0.000669
Train Epoch: 6 [17440/19430 (90%)] Loss: 0.000545
Train Epoch: 6 [17600/19430 (91%)] Loss: 0.000844
Train Epoch: 6 [17760/19430 (91%)] Loss: 0.017517
Train Epoch: 6 [17920/19430 (92%)] Loss: 0.027812
Train Epoch: 6 [18080/19430 (93%)] Loss: 0.055702
Train Epoch: 6 [18240/19430 (94%)] Loss: 0.007004
Train Epoch: 6 [18400/19430 (95%)] Loss: 0.010839
Train Epoch: 6 [18560/19430 (96%)] Loss: 0.002240
Train Epoch: 6 [18720/19430 (96%)] Loss: 0.015300
Train Epoch: 6 [18880/19430 (97%)] Loss: 0.013404
Train Epoch: 6 [19040/19430 (98%)] Loss: 0.004896
Train Epoch: 6 [19200/19430 (99%)] Loss: 0.004238
Train Epoch: 6 [19360/19430 (100%)] Loss: 0.007703
    epoch          : 6
    Train_loss     : 0.03365093876893872
    Train_accuracy : 0.990234375
    Train_f1_score : 0.990234375
    Val_loss       : 0.1203056396180353
    Val_accuracy   : 0.9713760504201681
    Val_f1_score   : 0.9713760614395142
Saving checkpoint: saved/models/efficientnet-b7-pretrained/1028_095732/checkpoint-epoch6.pth ...
Train Epoch: 7 [0/19430 (0%)] Loss: 0.088892
Train Epoch: 7 [160/19430 (1%)] Loss: 0.054460
Train Epoch: 7 [320/19430 (2%)] Loss: 0.001060
Train Epoch: 7 [480/19430 (2%)] Loss: 0.009311
Train Epoch: 7 [640/19430 (3%)] Loss: 0.001999
Train Epoch: 7 [800/19430 (4%)] Loss: 0.002997
Train Epoch: 7 [960/19430 (5%)] Loss: 0.000935
Train Epoch: 7 [1120/19430 (6%)] Loss: 0.019283
Train Epoch: 7 [1280/19430 (7%)] Loss: 0.024642
Train Epoch: 7 [1440/19430 (7%)] Loss: 0.002882
Train Epoch: 7 [1600/19430 (8%)] Loss: 0.001098
Train Epoch: 7 [1760/19430 (9%)] Loss: 0.016410
Train Epoch: 7 [1920/19430 (10%)] Loss: 0.002572
Train Epoch: 7 [2080/19430 (11%)] Loss: 0.022457
Train Epoch: 7 [2240/19430 (12%)] Loss: 0.004057
Train Epoch: 7 [2400/19430 (12%)] Loss: 0.011177
Train Epoch: 7 [2560/19430 (13%)] Loss: 0.004640
Train Epoch: 7 [2720/19430 (14%)] Loss: 0.002507
Train Epoch: 7 [2880/19430 (15%)] Loss: 0.163866
Train Epoch: 7 [3040/19430 (16%)] Loss: 0.183945
Train Epoch: 7 [3200/19430 (16%)] Loss: 0.027431
Train Epoch: 7 [3360/19430 (17%)] Loss: 0.003060
Train Epoch: 7 [3520/19430 (18%)] Loss: 0.014674
Train Epoch: 7 [3680/19430 (19%)] Loss: 0.006195
Train Epoch: 7 [3840/19430 (20%)] Loss: 0.003569
Train Epoch: 7 [4000/19430 (21%)] Loss: 0.005375
Train Epoch: 7 [4160/19430 (21%)] Loss: 0.006228
Train Epoch: 7 [4320/19430 (22%)] Loss: 0.004956
Train Epoch: 7 [4480/19430 (23%)] Loss: 0.006082
Train Epoch: 7 [4640/19430 (24%)] Loss: 0.005496
Train Epoch: 7 [4800/19430 (25%)] Loss: 0.002061
Train Epoch: 7 [4960/19430 (26%)] Loss: 0.000640
Train Epoch: 7 [5120/19430 (26%)] Loss: 0.032567
Train Epoch: 7 [5280/19430 (27%)] Loss: 0.059560
Train Epoch: 7 [5440/19430 (28%)] Loss: 0.006840
Train Epoch: 7 [5600/19430 (29%)] Loss: 0.006996
Train Epoch: 7 [5760/19430 (30%)] Loss: 0.000828
Train Epoch: 7 [5920/19430 (30%)] Loss: 0.065615
Train Epoch: 7 [6080/19430 (31%)] Loss: 0.001110
Train Epoch: 7 [6240/19430 (32%)] Loss: 0.000764
Train Epoch: 7 [6400/19430 (33%)] Loss: 0.046955
Train Epoch: 7 [6560/19430 (34%)] Loss: 0.142760
Train Epoch: 7 [6720/19430 (35%)] Loss: 0.001756
Train Epoch: 7 [6880/19430 (35%)] Loss: 0.001812
Train Epoch: 7 [7040/19430 (36%)] Loss: 0.000454
Train Epoch: 7 [7200/19430 (37%)] Loss: 0.000630
Train Epoch: 7 [7360/19430 (38%)] Loss: 0.003612
Train Epoch: 7 [7520/19430 (39%)] Loss: 0.061896
Train Epoch: 7 [7680/19430 (40%)] Loss: 0.012139
Train Epoch: 7 [7840/19430 (40%)] Loss: 0.010026
Train Epoch: 7 [8000/19430 (41%)] Loss: 0.000927
Train Epoch: 7 [8160/19430 (42%)] Loss: 0.004840
Train Epoch: 7 [8320/19430 (43%)] Loss: 0.004941
Train Epoch: 7 [8480/19430 (44%)] Loss: 0.001669
Train Epoch: 7 [8640/19430 (44%)] Loss: 0.030454
Train Epoch: 7 [8800/19430 (45%)] Loss: 0.000441
Train Epoch: 7 [8960/19430 (46%)] Loss: 0.002904
Train Epoch: 7 [9120/19430 (47%)] Loss: 0.000628
Train Epoch: 7 [9280/19430 (48%)] Loss: 0.000711
Train Epoch: 7 [9440/19430 (49%)] Loss: 0.001203
Train Epoch: 7 [9600/19430 (49%)] Loss: 0.087294
Train Epoch: 7 [9760/19430 (50%)] Loss: 0.001173
Train Epoch: 7 [9920/19430 (51%)] Loss: 0.043991
Train Epoch: 7 [10080/19430 (52%)] Loss: 0.030949
Train Epoch: 7 [10240/19430 (53%)] Loss: 0.001331
Train Epoch: 7 [10400/19430 (54%)] Loss: 0.008976
Train Epoch: 7 [10560/19430 (54%)] Loss: 0.000717
Train Epoch: 7 [10720/19430 (55%)] Loss: 0.020547
Train Epoch: 7 [10880/19430 (56%)] Loss: 0.004620
Train Epoch: 7 [11040/19430 (57%)] Loss: 0.008311
Train Epoch: 7 [11200/19430 (58%)] Loss: 0.001427
Train Epoch: 7 [11360/19430 (58%)] Loss: 0.008163
Train Epoch: 7 [11520/19430 (59%)] Loss: 0.008267
Train Epoch: 7 [11680/19430 (60%)] Loss: 0.013276
Train Epoch: 7 [11840/19430 (61%)] Loss: 0.002103
Train Epoch: 7 [12000/19430 (62%)] Loss: 0.166380
Train Epoch: 7 [12160/19430 (63%)] Loss: 0.007849
Train Epoch: 7 [12320/19430 (63%)] Loss: 0.060375
Train Epoch: 7 [12480/19430 (64%)] Loss: 0.001140
Train Epoch: 7 [12640/19430 (65%)] Loss: 0.031617
Train Epoch: 7 [12800/19430 (66%)] Loss: 0.024810
Train Epoch: 7 [12960/19430 (67%)] Loss: 0.006267
Train Epoch: 7 [13120/19430 (68%)] Loss: 0.014271
Train Epoch: 7 [13280/19430 (68%)] Loss: 0.001888
Train Epoch: 7 [13440/19430 (69%)] Loss: 0.007269
Train Epoch: 7 [13600/19430 (70%)] Loss: 0.006384
Train Epoch: 7 [13760/19430 (71%)] Loss: 0.008846
Train Epoch: 7 [13920/19430 (72%)] Loss: 0.001365
Train Epoch: 7 [14080/19430 (72%)] Loss: 0.020621
Train Epoch: 7 [14240/19430 (73%)] Loss: 0.004498
Train Epoch: 7 [14400/19430 (74%)] Loss: 0.001728
Train Epoch: 7 [14560/19430 (75%)] Loss: 0.000471
Train Epoch: 7 [14720/19430 (76%)] Loss: 0.000886
Train Epoch: 7 [14880/19430 (77%)] Loss: 0.006072
Train Epoch: 7 [15040/19430 (77%)] Loss: 0.005728
Train Epoch: 7 [15200/19430 (78%)] Loss: 0.000925
Train Epoch: 7 [15360/19430 (79%)] Loss: 0.052403
Train Epoch: 7 [15520/19430 (80%)] Loss: 0.001534
Train Epoch: 7 [15680/19430 (81%)] Loss: 0.012210
Train Epoch: 7 [15840/19430 (82%)] Loss: 0.000913
Train Epoch: 7 [16000/19430 (82%)] Loss: 0.028062
Train Epoch: 7 [16160/19430 (83%)] Loss: 0.008058
Train Epoch: 7 [16320/19430 (84%)] Loss: 0.021615
Train Epoch: 7 [16480/19430 (85%)] Loss: 0.163429
Train Epoch: 7 [16640/19430 (86%)] Loss: 0.002340
Train Epoch: 7 [16800/19430 (86%)] Loss: 0.001592
Train Epoch: 7 [16960/19430 (87%)] Loss: 0.006375
Train Epoch: 7 [17120/19430 (88%)] Loss: 0.015662
Train Epoch: 7 [17280/19430 (89%)] Loss: 0.002401
Train Epoch: 7 [17440/19430 (90%)] Loss: 0.001450
Train Epoch: 7 [17600/19430 (91%)] Loss: 0.000880
Train Epoch: 7 [17760/19430 (91%)] Loss: 0.001935
Train Epoch: 7 [17920/19430 (92%)] Loss: 0.004531
Train Epoch: 7 [18080/19430 (93%)] Loss: 0.024667
Train Epoch: 7 [18240/19430 (94%)] Loss: 0.007366
Train Epoch: 7 [18400/19430 (95%)] Loss: 0.011507
Train Epoch: 7 [18560/19430 (96%)] Loss: 0.001746
Train Epoch: 7 [18720/19430 (96%)] Loss: 0.004219
Train Epoch: 7 [18880/19430 (97%)] Loss: 0.146887
Train Epoch: 7 [19040/19430 (98%)] Loss: 0.131562
Train Epoch: 7 [19200/19430 (99%)] Loss: 0.009537
Train Epoch: 7 [19360/19430 (100%)] Loss: 0.001204
    epoch          : 7
    Train_loss     : 0.028334745053191574
    Train_accuracy : 0.9914336622807017
    Train_f1_score : 0.9914336800575256
    Val_loss       : 0.08915254827297758
    Val_accuracy   : 0.9779411764705882
    Val_f1_score   : 0.9779411554336548
Train Epoch: 8 [0/19430 (0%)] Loss: 0.035615
Train Epoch: 8 [160/19430 (1%)] Loss: 0.542122
Train Epoch: 8 [320/19430 (2%)] Loss: 0.168052
Train Epoch: 8 [480/19430 (2%)] Loss: 0.066276
Train Epoch: 8 [640/19430 (3%)] Loss: 0.254038
Train Epoch: 8 [800/19430 (4%)] Loss: 0.047238
Train Epoch: 8 [960/19430 (5%)] Loss: 0.055791
Train Epoch: 8 [1120/19430 (6%)] Loss: 0.082001
Train Epoch: 8 [1280/19430 (7%)] Loss: 0.022952
Train Epoch: 8 [1440/19430 (7%)] Loss: 0.015703
Train Epoch: 8 [1600/19430 (8%)] Loss: 0.218587
Train Epoch: 8 [1760/19430 (9%)] Loss: 0.058414
Train Epoch: 8 [1920/19430 (10%)] Loss: 0.065534
Train Epoch: 8 [2080/19430 (11%)] Loss: 0.019579
Train Epoch: 8 [2240/19430 (12%)] Loss: 0.016249
Train Epoch: 8 [2400/19430 (12%)] Loss: 0.051386
Train Epoch: 8 [2560/19430 (13%)] Loss: 0.032516
Train Epoch: 8 [2720/19430 (14%)] Loss: 0.061593
Train Epoch: 8 [2880/19430 (15%)] Loss: 0.155641
Train Epoch: 8 [3040/19430 (16%)] Loss: 0.066958
Train Epoch: 8 [3200/19430 (16%)] Loss: 0.254517
Train Epoch: 8 [3360/19430 (17%)] Loss: 0.091696
Train Epoch: 8 [3520/19430 (18%)] Loss: 0.004691
Train Epoch: 8 [3680/19430 (19%)] Loss: 0.009593
Train Epoch: 8 [3840/19430 (20%)] Loss: 0.018258
Train Epoch: 8 [4000/19430 (21%)] Loss: 0.006083
Train Epoch: 8 [4160/19430 (21%)] Loss: 0.001848
Train Epoch: 8 [4320/19430 (22%)] Loss: 0.009254
Train Epoch: 8 [4480/19430 (23%)] Loss: 0.004829
Train Epoch: 8 [4640/19430 (24%)] Loss: 0.008744
Train Epoch: 8 [4800/19430 (25%)] Loss: 0.009051
Train Epoch: 8 [4960/19430 (26%)] Loss: 0.007653
Train Epoch: 8 [5120/19430 (26%)] Loss: 0.064440
Train Epoch: 8 [5280/19430 (27%)] Loss: 0.117521
Train Epoch: 8 [5440/19430 (28%)] Loss: 0.009903
Train Epoch: 8 [5600/19430 (29%)] Loss: 0.070894
Train Epoch: 8 [5760/19430 (30%)] Loss: 0.005904
Train Epoch: 8 [5920/19430 (30%)] Loss: 0.005086
Train Epoch: 8 [6080/19430 (31%)] Loss: 0.096111
Train Epoch: 8 [6240/19430 (32%)] Loss: 0.040063
Train Epoch: 8 [6400/19430 (33%)] Loss: 0.010426
Train Epoch: 8 [6560/19430 (34%)] Loss: 0.015562
Train Epoch: 8 [6720/19430 (35%)] Loss: 0.130709
Train Epoch: 8 [6880/19430 (35%)] Loss: 0.015834
Train Epoch: 8 [7040/19430 (36%)] Loss: 0.008134
Train Epoch: 8 [7200/19430 (37%)] Loss: 0.003855
Train Epoch: 8 [7360/19430 (38%)] Loss: 0.124116
Train Epoch: 8 [7520/19430 (39%)] Loss: 0.108061
Train Epoch: 8 [7680/19430 (40%)] Loss: 0.005251
Train Epoch: 8 [7840/19430 (40%)] Loss: 0.031932
Train Epoch: 8 [8000/19430 (41%)] Loss: 0.001820
Train Epoch: 8 [8160/19430 (42%)] Loss: 0.108232
Train Epoch: 8 [8320/19430 (43%)] Loss: 0.093359
Train Epoch: 8 [8480/19430 (44%)] Loss: 0.007211
Train Epoch: 8 [8640/19430 (44%)] Loss: 0.101998
Train Epoch: 8 [8800/19430 (45%)] Loss: 0.004349
Train Epoch: 8 [8960/19430 (46%)] Loss: 0.012002
Train Epoch: 8 [9120/19430 (47%)] Loss: 0.031076
Train Epoch: 8 [9280/19430 (48%)] Loss: 0.014211
Train Epoch: 8 [9440/19430 (49%)] Loss: 0.021206
Train Epoch: 8 [9600/19430 (49%)] Loss: 0.033726
Train Epoch: 8 [9760/19430 (50%)] Loss: 0.001830
Train Epoch: 8 [9920/19430 (51%)] Loss: 0.002074
Train Epoch: 8 [10080/19430 (52%)] Loss: 0.002935
Train Epoch: 8 [10240/19430 (53%)] Loss: 0.019781
Train Epoch: 8 [10400/19430 (54%)] Loss: 0.005185
Train Epoch: 8 [10560/19430 (54%)] Loss: 0.000811
Train Epoch: 8 [10720/19430 (55%)] Loss: 0.004041
Train Epoch: 8 [10880/19430 (56%)] Loss: 0.004115
Train Epoch: 8 [11040/19430 (57%)] Loss: 0.001006
Train Epoch: 8 [11200/19430 (58%)] Loss: 0.005387
Train Epoch: 8 [11360/19430 (58%)] Loss: 0.001061
Train Epoch: 8 [11520/19430 (59%)] Loss: 0.138170
Train Epoch: 8 [11680/19430 (60%)] Loss: 0.002532
Train Epoch: 8 [11840/19430 (61%)] Loss: 0.022009
Train Epoch: 8 [12000/19430 (62%)] Loss: 0.002587
Train Epoch: 8 [12160/19430 (63%)] Loss: 0.002070
Train Epoch: 8 [12320/19430 (63%)] Loss: 0.001342
Train Epoch: 8 [12480/19430 (64%)] Loss: 0.011885
Train Epoch: 8 [12640/19430 (65%)] Loss: 0.011517
Train Epoch: 8 [12800/19430 (66%)] Loss: 0.001670
Train Epoch: 8 [12960/19430 (67%)] Loss: 0.011257
Train Epoch: 8 [13120/19430 (68%)] Loss: 0.015661
Train Epoch: 8 [13280/19430 (68%)] Loss: 0.006730
Train Epoch: 8 [13440/19430 (69%)] Loss: 0.059003
Train Epoch: 8 [13600/19430 (70%)] Loss: 0.000518
Train Epoch: 8 [13760/19430 (71%)] Loss: 0.017157
Train Epoch: 8 [13920/19430 (72%)] Loss: 0.004089
Train Epoch: 8 [14080/19430 (72%)] Loss: 0.000719
Train Epoch: 8 [14240/19430 (73%)] Loss: 0.003494
Train Epoch: 8 [14400/19430 (74%)] Loss: 0.032125
Train Epoch: 8 [14560/19430 (75%)] Loss: 0.013532
Train Epoch: 8 [14720/19430 (76%)] Loss: 0.074931
Train Epoch: 8 [14880/19430 (77%)] Loss: 0.001930
Train Epoch: 8 [15040/19430 (77%)] Loss: 0.064842
Train Epoch: 8 [15200/19430 (78%)] Loss: 0.014625
Train Epoch: 8 [15360/19430 (79%)] Loss: 0.005256
Train Epoch: 8 [15520/19430 (80%)] Loss: 0.002462
Train Epoch: 8 [15680/19430 (81%)] Loss: 0.010814
Train Epoch: 8 [15840/19430 (82%)] Loss: 0.166666
Train Epoch: 8 [16000/19430 (82%)] Loss: 0.046241
Train Epoch: 8 [16160/19430 (83%)] Loss: 0.007517
Train Epoch: 8 [16320/19430 (84%)] Loss: 0.002849
Train Epoch: 8 [16480/19430 (85%)] Loss: 0.016908
Train Epoch: 8 [16640/19430 (86%)] Loss: 0.001899
Train Epoch: 8 [16800/19430 (86%)] Loss: 0.001198
Train Epoch: 8 [16960/19430 (87%)] Loss: 0.005007
Train Epoch: 8 [17120/19430 (88%)] Loss: 0.041580
Train Epoch: 8 [17280/19430 (89%)] Loss: 0.009273
Train Epoch: 8 [17440/19430 (90%)] Loss: 0.003759
Train Epoch: 8 [17600/19430 (91%)] Loss: 0.003848
Train Epoch: 8 [17760/19430 (91%)] Loss: 0.005510
Train Epoch: 8 [17920/19430 (92%)] Loss: 0.262638
Train Epoch: 8 [18080/19430 (93%)] Loss: 0.093593
Train Epoch: 8 [18240/19430 (94%)] Loss: 0.003523
Train Epoch: 8 [18400/19430 (95%)] Loss: 0.014136
Train Epoch: 8 [18560/19430 (96%)] Loss: 0.012513
Train Epoch: 8 [18720/19430 (96%)] Loss: 0.102549
Train Epoch: 8 [18880/19430 (97%)] Loss: 0.062643
Train Epoch: 8 [19040/19430 (98%)] Loss: 0.015174
Train Epoch: 8 [19200/19430 (99%)] Loss: 0.000889
Train Epoch: 8 [19360/19430 (100%)] Loss: 0.156884
    epoch          : 8
    Train_loss     : 0.042534411069362635
    Train_accuracy : 0.986585115131579
    Train_f1_score : 0.9865851402282715
    Val_loss       : 0.11145848974924508
    Val_accuracy   : 0.9765625
    Val_f1_score   : 0.9765625
Saving checkpoint: saved/models/efficientnet-b7-pretrained/1028_095732/checkpoint-epoch8.pth ...
Train Epoch: 9 [0/19430 (0%)] Loss: 0.229207
Train Epoch: 9 [160/19430 (1%)] Loss: 0.061705
Train Epoch: 9 [320/19430 (2%)] Loss: 0.007586
Train Epoch: 9 [480/19430 (2%)] Loss: 0.004678
Train Epoch: 9 [640/19430 (3%)] Loss: 0.013620
Train Epoch: 9 [800/19430 (4%)] Loss: 0.019897
Train Epoch: 9 [960/19430 (5%)] Loss: 0.082822
Train Epoch: 9 [1120/19430 (6%)] Loss: 0.001061
Train Epoch: 9 [1280/19430 (7%)] Loss: 0.001688
Train Epoch: 9 [1440/19430 (7%)] Loss: 0.415655
Train Epoch: 9 [1600/19430 (8%)] Loss: 0.005533
Train Epoch: 9 [1760/19430 (9%)] Loss: 0.002068
Train Epoch: 9 [1920/19430 (10%)] Loss: 0.018561
Train Epoch: 9 [2080/19430 (11%)] Loss: 0.003588
Train Epoch: 9 [2240/19430 (12%)] Loss: 0.006106
Train Epoch: 9 [2400/19430 (12%)] Loss: 0.005689
Train Epoch: 9 [2560/19430 (13%)] Loss: 0.000671
Train Epoch: 9 [2720/19430 (14%)] Loss: 0.007293
Train Epoch: 9 [2880/19430 (15%)] Loss: 0.019374
Train Epoch: 9 [3040/19430 (16%)] Loss: 0.002521
Train Epoch: 9 [3200/19430 (16%)] Loss: 0.003495
Train Epoch: 9 [3360/19430 (17%)] Loss: 0.006122
Train Epoch: 9 [3520/19430 (18%)] Loss: 0.266296
Train Epoch: 9 [3680/19430 (19%)] Loss: 0.001063
Train Epoch: 9 [3840/19430 (20%)] Loss: 0.004312
Train Epoch: 9 [4000/19430 (21%)] Loss: 0.014021
Train Epoch: 9 [4160/19430 (21%)] Loss: 0.060388
Train Epoch: 9 [4320/19430 (22%)] Loss: 0.019415
Train Epoch: 9 [4480/19430 (23%)] Loss: 0.003849
Train Epoch: 9 [4640/19430 (24%)] Loss: 0.168830
Train Epoch: 9 [4800/19430 (25%)] Loss: 0.016247
Train Epoch: 9 [4960/19430 (26%)] Loss: 0.002495
Train Epoch: 9 [5120/19430 (26%)] Loss: 0.001707
Train Epoch: 9 [5280/19430 (27%)] Loss: 0.010400
Train Epoch: 9 [5440/19430 (28%)] Loss: 0.013303
Train Epoch: 9 [5600/19430 (29%)] Loss: 0.000524
Train Epoch: 9 [5760/19430 (30%)] Loss: 0.019674
Train Epoch: 9 [5920/19430 (30%)] Loss: 0.006455
Train Epoch: 9 [6080/19430 (31%)] Loss: 0.002384
Train Epoch: 9 [6240/19430 (32%)] Loss: 0.218379
Train Epoch: 9 [6400/19430 (33%)] Loss: 0.031794
Train Epoch: 9 [6560/19430 (34%)] Loss: 0.003415
Train Epoch: 9 [6720/19430 (35%)] Loss: 0.004224
Train Epoch: 9 [6880/19430 (35%)] Loss: 0.002753
Train Epoch: 9 [7040/19430 (36%)] Loss: 0.011993
Train Epoch: 9 [7200/19430 (37%)] Loss: 0.004633
Train Epoch: 9 [7360/19430 (38%)] Loss: 0.055904
Train Epoch: 9 [7520/19430 (39%)] Loss: 0.001714
Train Epoch: 9 [7680/19430 (40%)] Loss: 0.003007
Train Epoch: 9 [7840/19430 (40%)] Loss: 0.095816
Train Epoch: 9 [8000/19430 (41%)] Loss: 0.018331
Train Epoch: 9 [8160/19430 (42%)] Loss: 0.006036
Train Epoch: 9 [8320/19430 (43%)] Loss: 0.006769
Train Epoch: 9 [8480/19430 (44%)] Loss: 0.001969
Train Epoch: 9 [8640/19430 (44%)] Loss: 0.001307
Train Epoch: 9 [8800/19430 (45%)] Loss: 0.349999
Train Epoch: 9 [8960/19430 (46%)] Loss: 0.003309
Train Epoch: 9 [9120/19430 (47%)] Loss: 0.001772
Train Epoch: 9 [9280/19430 (48%)] Loss: 0.003356
Train Epoch: 9 [9440/19430 (49%)] Loss: 0.008694
Train Epoch: 9 [9600/19430 (49%)] Loss: 0.001507
Train Epoch: 9 [9760/19430 (50%)] Loss: 0.000753
Train Epoch: 9 [9920/19430 (51%)] Loss: 0.007915
Train Epoch: 9 [10080/19430 (52%)] Loss: 0.024542
Train Epoch: 9 [10240/19430 (53%)] Loss: 0.010011
Train Epoch: 9 [10400/19430 (54%)] Loss: 0.005595
Train Epoch: 9 [10560/19430 (54%)] Loss: 0.029820
Train Epoch: 9 [10720/19430 (55%)] Loss: 0.009109
Train Epoch: 9 [10880/19430 (56%)] Loss: 0.001537
Train Epoch: 9 [11040/19430 (57%)] Loss: 0.004825
Train Epoch: 9 [11200/19430 (58%)] Loss: 0.630815
Train Epoch: 9 [11360/19430 (58%)] Loss: 0.000975
Train Epoch: 9 [11520/19430 (59%)] Loss: 0.017783
Train Epoch: 9 [11680/19430 (60%)] Loss: 0.002134
Train Epoch: 9 [11840/19430 (61%)] Loss: 0.019445
Train Epoch: 9 [12000/19430 (62%)] Loss: 0.002345
Train Epoch: 9 [12160/19430 (63%)] Loss: 0.002396
Train Epoch: 9 [12320/19430 (63%)] Loss: 0.018357
Train Epoch: 9 [12480/19430 (64%)] Loss: 0.004822
Train Epoch: 9 [12640/19430 (65%)] Loss: 0.000657
Train Epoch: 9 [12800/19430 (66%)] Loss: 0.001597
Train Epoch: 9 [12960/19430 (67%)] Loss: 0.000851
Train Epoch: 9 [13120/19430 (68%)] Loss: 0.013145
Train Epoch: 9 [13280/19430 (68%)] Loss: 0.001966
Train Epoch: 9 [13440/19430 (69%)] Loss: 0.026098
Train Epoch: 9 [13600/19430 (70%)] Loss: 0.000921
Train Epoch: 9 [13760/19430 (71%)] Loss: 0.000815
Train Epoch: 9 [13920/19430 (72%)] Loss: 0.053287
Train Epoch: 9 [14080/19430 (72%)] Loss: 0.086049
Train Epoch: 9 [14240/19430 (73%)] Loss: 0.000629
Train Epoch: 9 [14400/19430 (74%)] Loss: 0.008477
Train Epoch: 9 [14560/19430 (75%)] Loss: 0.006210
Train Epoch: 9 [14720/19430 (76%)] Loss: 0.001329
Train Epoch: 9 [14880/19430 (77%)] Loss: 0.002828
Train Epoch: 9 [15040/19430 (77%)] Loss: 0.000671
Train Epoch: 9 [15200/19430 (78%)] Loss: 0.053684
Train Epoch: 9 [15360/19430 (79%)] Loss: 0.040939
Train Epoch: 9 [15520/19430 (80%)] Loss: 0.003529
Train Epoch: 9 [15680/19430 (81%)] Loss: 0.082341
Train Epoch: 9 [15840/19430 (82%)] Loss: 0.010962
Train Epoch: 9 [16000/19430 (82%)] Loss: 0.001192
Train Epoch: 9 [16160/19430 (83%)] Loss: 0.045043
Train Epoch: 9 [16320/19430 (84%)] Loss: 0.002204
Train Epoch: 9 [16480/19430 (85%)] Loss: 0.205286
Train Epoch: 9 [16640/19430 (86%)] Loss: 0.005324
Train Epoch: 9 [16800/19430 (86%)] Loss: 0.001256
Train Epoch: 9 [16960/19430 (87%)] Loss: 0.001114
Train Epoch: 9 [17120/19430 (88%)] Loss: 0.001881
Train Epoch: 9 [17280/19430 (89%)] Loss: 0.000973
Train Epoch: 9 [17440/19430 (90%)] Loss: 0.000807
Train Epoch: 9 [17600/19430 (91%)] Loss: 0.002366
Train Epoch: 9 [17760/19430 (91%)] Loss: 0.013975
Train Epoch: 9 [17920/19430 (92%)] Loss: 0.002978
Train Epoch: 9 [18080/19430 (93%)] Loss: 0.201634
Train Epoch: 9 [18240/19430 (94%)] Loss: 0.032460
Train Epoch: 9 [18400/19430 (95%)] Loss: 0.001276
Train Epoch: 9 [18560/19430 (96%)] Loss: 0.012385
Train Epoch: 9 [18720/19430 (96%)] Loss: 0.031283
Train Epoch: 9 [18880/19430 (97%)] Loss: 0.000430
Train Epoch: 9 [19040/19430 (98%)] Loss: 0.003691
Train Epoch: 9 [19200/19430 (99%)] Loss: 0.134928
Train Epoch: 9 [19360/19430 (100%)] Loss: 0.160835
    epoch          : 9
    Train_loss     : 0.024096263289768678
    Train_accuracy : 0.9925472861842105
    Train_f1_score : 0.9925472736358643
    Val_loss       : 0.07622271629824194
    Val_accuracy   : 0.9774816176470589
    Val_f1_score   : 0.9774816036224365
Train Epoch: 10 [0/19430 (0%)] Loss: 0.026645
Train Epoch: 10 [160/19430 (1%)] Loss: 0.001484
Train Epoch: 10 [320/19430 (2%)] Loss: 0.000420
Train Epoch: 10 [480/19430 (2%)] Loss: 0.044496
Train Epoch: 10 [640/19430 (3%)] Loss: 0.008336
Train Epoch: 10 [800/19430 (4%)] Loss: 0.017545
Train Epoch: 10 [960/19430 (5%)] Loss: 0.001366
Train Epoch: 10 [1120/19430 (6%)] Loss: 0.001428
Train Epoch: 10 [1280/19430 (7%)] Loss: 0.007727
Train Epoch: 10 [1440/19430 (7%)] Loss: 0.002021
Train Epoch: 10 [1600/19430 (8%)] Loss: 0.004611
Train Epoch: 10 [1760/19430 (9%)] Loss: 0.000691
Train Epoch: 10 [1920/19430 (10%)] Loss: 0.000358
Train Epoch: 10 [2080/19430 (11%)] Loss: 0.002894
Train Epoch: 10 [2240/19430 (12%)] Loss: 0.017985
Train Epoch: 10 [2400/19430 (12%)] Loss: 0.000603
Train Epoch: 10 [2560/19430 (13%)] Loss: 0.000519
Train Epoch: 10 [2720/19430 (14%)] Loss: 0.002693
Train Epoch: 10 [2880/19430 (15%)] Loss: 0.001190
Train Epoch: 10 [3040/19430 (16%)] Loss: 0.000114
Train Epoch: 10 [3200/19430 (16%)] Loss: 0.006763
Train Epoch: 10 [3360/19430 (17%)] Loss: 0.003602
Train Epoch: 10 [3520/19430 (18%)] Loss: 0.010074
Train Epoch: 10 [3680/19430 (19%)] Loss: 0.000568
Train Epoch: 10 [3840/19430 (20%)] Loss: 0.002405
Train Epoch: 10 [4000/19430 (21%)] Loss: 0.002952
Train Epoch: 10 [4160/19430 (21%)] Loss: 0.015730
Train Epoch: 10 [4320/19430 (22%)] Loss: 0.001188
Train Epoch: 10 [4480/19430 (23%)] Loss: 0.006755
Train Epoch: 10 [4640/19430 (24%)] Loss: 0.000264
Train Epoch: 10 [4800/19430 (25%)] Loss: 0.001501
Train Epoch: 10 [4960/19430 (26%)] Loss: 0.035069
Train Epoch: 10 [5120/19430 (26%)] Loss: 0.018646
Train Epoch: 10 [5280/19430 (27%)] Loss: 0.000831
Train Epoch: 10 [5440/19430 (28%)] Loss: 0.000785
Train Epoch: 10 [5600/19430 (29%)] Loss: 0.000524
Train Epoch: 10 [5760/19430 (30%)] Loss: 0.001819
Train Epoch: 10 [5920/19430 (30%)] Loss: 0.003708
Train Epoch: 10 [6080/19430 (31%)] Loss: 0.014091
Train Epoch: 10 [6240/19430 (32%)] Loss: 0.000901
Train Epoch: 10 [6400/19430 (33%)] Loss: 0.062676
Train Epoch: 10 [6560/19430 (34%)] Loss: 0.000307
Train Epoch: 10 [6720/19430 (35%)] Loss: 0.000669
Train Epoch: 10 [6880/19430 (35%)] Loss: 0.018990
Train Epoch: 10 [7040/19430 (36%)] Loss: 0.002990
Train Epoch: 10 [7200/19430 (37%)] Loss: 0.001001
Train Epoch: 10 [7360/19430 (38%)] Loss: 0.001108
Train Epoch: 10 [7520/19430 (39%)] Loss: 0.079426
Train Epoch: 10 [7680/19430 (40%)] Loss: 0.001525
Train Epoch: 10 [7840/19430 (40%)] Loss: 0.001081
Train Epoch: 10 [8000/19430 (41%)] Loss: 0.001831
Train Epoch: 10 [8160/19430 (42%)] Loss: 0.003483
Train Epoch: 10 [8320/19430 (43%)] Loss: 0.000829
Train Epoch: 10 [8480/19430 (44%)] Loss: 0.004882
Train Epoch: 10 [8640/19430 (44%)] Loss: 0.022990
Train Epoch: 10 [8800/19430 (45%)] Loss: 0.003024
Train Epoch: 10 [8960/19430 (46%)] Loss: 0.001268
Train Epoch: 10 [9120/19430 (47%)] Loss: 0.003300
Train Epoch: 10 [9280/19430 (48%)] Loss: 0.034946
Train Epoch: 10 [9440/19430 (49%)] Loss: 0.010173
Train Epoch: 10 [9600/19430 (49%)] Loss: 0.015207
Train Epoch: 10 [9760/19430 (50%)] Loss: 0.002337
Train Epoch: 10 [9920/19430 (51%)] Loss: 0.011083
Train Epoch: 10 [10080/19430 (52%)] Loss: 0.013005
Train Epoch: 10 [10240/19430 (53%)] Loss: 0.151892
Train Epoch: 10 [10400/19430 (54%)] Loss: 0.002372
Train Epoch: 10 [10560/19430 (54%)] Loss: 0.001224
Train Epoch: 10 [10720/19430 (55%)] Loss: 0.000623
Train Epoch: 10 [10880/19430 (56%)] Loss: 0.000561
Train Epoch: 10 [11040/19430 (57%)] Loss: 0.001835
Train Epoch: 10 [11200/19430 (58%)] Loss: 0.001237
Train Epoch: 10 [11360/19430 (58%)] Loss: 0.031576
Train Epoch: 10 [11520/19430 (59%)] Loss: 0.019666
Train Epoch: 10 [11680/19430 (60%)] Loss: 0.015672
Train Epoch: 10 [11840/19430 (61%)] Loss: 0.000778
Train Epoch: 10 [12000/19430 (62%)] Loss: 0.000986
Train Epoch: 10 [12160/19430 (63%)] Loss: 0.009706
Train Epoch: 10 [12320/19430 (63%)] Loss: 0.000529
Train Epoch: 10 [12480/19430 (64%)] Loss: 0.043390
Train Epoch: 10 [12640/19430 (65%)] Loss: 0.009563
Train Epoch: 10 [12800/19430 (66%)] Loss: 0.005023
Train Epoch: 10 [12960/19430 (67%)] Loss: 0.012599
Train Epoch: 10 [13120/19430 (68%)] Loss: 0.000155
Train Epoch: 10 [13280/19430 (68%)] Loss: 0.049683
Train Epoch: 10 [13440/19430 (69%)] Loss: 0.007169
Train Epoch: 10 [13600/19430 (70%)] Loss: 0.087330
Train Epoch: 10 [13760/19430 (71%)] Loss: 0.004379
Train Epoch: 10 [13920/19430 (72%)] Loss: 0.001650
Train Epoch: 10 [14080/19430 (72%)] Loss: 0.001626
Train Epoch: 10 [14240/19430 (73%)] Loss: 0.050107
Train Epoch: 10 [14400/19430 (74%)] Loss: 0.041374
Train Epoch: 10 [14560/19430 (75%)] Loss: 0.012009
Train Epoch: 10 [14720/19430 (76%)] Loss: 0.116986
Train Epoch: 10 [14880/19430 (77%)] Loss: 0.010283
Train Epoch: 10 [15040/19430 (77%)] Loss: 0.002143
Train Epoch: 10 [15200/19430 (78%)] Loss: 0.001446
Train Epoch: 10 [15360/19430 (79%)] Loss: 0.002547
Train Epoch: 10 [15520/19430 (80%)] Loss: 0.000425
Train Epoch: 10 [15680/19430 (81%)] Loss: 0.069376
Train Epoch: 10 [15840/19430 (82%)] Loss: 0.000568
Train Epoch: 10 [16000/19430 (82%)] Loss: 0.001621
Train Epoch: 10 [16160/19430 (83%)] Loss: 0.004832
Train Epoch: 10 [16320/19430 (84%)] Loss: 0.017732
Train Epoch: 10 [16480/19430 (85%)] Loss: 0.006301
Train Epoch: 10 [16640/19430 (86%)] Loss: 0.000995
Train Epoch: 10 [16800/19430 (86%)] Loss: 0.026779
Train Epoch: 10 [16960/19430 (87%)] Loss: 0.001466
Train Epoch: 10 [17120/19430 (88%)] Loss: 0.076689
Train Epoch: 10 [17280/19430 (89%)] Loss: 0.001151
Train Epoch: 10 [17440/19430 (90%)] Loss: 0.000658
Train Epoch: 10 [17600/19430 (91%)] Loss: 0.079646
Train Epoch: 10 [17760/19430 (91%)] Loss: 0.016228
Train Epoch: 10 [17920/19430 (92%)] Loss: 0.000428
Train Epoch: 10 [18080/19430 (93%)] Loss: 0.009579
Train Epoch: 10 [18240/19430 (94%)] Loss: 0.000581
Train Epoch: 10 [18400/19430 (95%)] Loss: 0.066593
Train Epoch: 10 [18560/19430 (96%)] Loss: 0.001726
Train Epoch: 10 [18720/19430 (96%)] Loss: 0.013660
Train Epoch: 10 [18880/19430 (97%)] Loss: 0.007561
Train Epoch: 10 [19040/19430 (98%)] Loss: 0.018105
Train Epoch: 10 [19200/19430 (99%)] Loss: 0.002548
Train Epoch: 10 [19360/19430 (100%)] Loss: 0.000223
    epoch          : 10
    Train_loss     : 0.0189695594421042
    Train_accuracy : 0.9946546052631579
    Train_f1_score : 0.9946545958518982
    Val_loss       : 0.0856825876140005
    Val_accuracy   : 0.9773503151260504
    Val_f1_score   : 0.9773503541946411
Saving checkpoint: saved/models/efficientnet-b7-pretrained/1028_095732/checkpoint-epoch10.pth ...
/opt/conda/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.127 MB of 0.127 MB uploaded (0.000 MB deduped)wandb: | 0.127 MB of 0.127 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: Train_accuracy ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: Train_f1_score ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     Train_loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   Val_accuracy ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:   Val_f1_score ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:       Val_loss ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb: Train_accuracy 0.99465
wandb: Train_f1_score 0.99465
wandb:     Train_loss 0.01897
wandb:   Val_accuracy 0.97735
wandb:   Val_f1_score 0.97735
wandb:       Val_loss 0.08568
wandb: 
wandb: Synced bright-disco-36: https://wandb.ai/qwer55252/Boostcamp-lv1-cv1/runs/2rxznn66
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221028_095728-2rxznn66/logs
